{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1922c748",
   "metadata": {},
   "source": [
    "## Perubahan Struktur Dataset Pembelian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05774849",
   "metadata": {},
   "source": [
    "### Perubahan Struktur Dataset Pembelian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41225c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File 'pembelian_final_fix.csv' berhasil dibuat!\n",
      "       KODE NAMA_PRODUK   UNIT    TANGGAL          NO_TRANSAKSI  QTY_MSK  \\\n",
      "0   A000001  ANATON TAB  STRIP 2021-07-06  1.13-210706.0908-003     10.0   \n",
      "1   A000001  ANATON TAB  STRIP 2021-07-12   2.6-210712.1519-097      0.0   \n",
      "2   A000001  ANATON TAB  STRIP 2021-07-12  2.11-210712.1633-013      0.0   \n",
      "3   A000001  ANATON TAB  STRIP 2021-07-12  2.13-210712.1807-013      0.0   \n",
      "4   A000001  ANATON TAB  STRIP 2021-07-12  2.11-210712.1855-018      0.0   \n",
      "5   A000001  ANATON TAB  STRIP 2021-07-12  2.11-210712.1925-027      0.0   \n",
      "6   A000001  ANATON TAB  STRIP 2021-07-12  2.11-210712.1957-035      0.0   \n",
      "7   A000001  ANATON TAB  STRIP 2021-07-12   2.6-210712.0907-023      0.0   \n",
      "8   A000001  ANATON TAB  STRIP 2021-07-13  2.11-210713.1102-011      0.0   \n",
      "9   A000001  ANATON TAB  STRIP 2021-07-13   2.6-210713.1701-006      0.0   \n",
      "10  A000001  ANATON TAB  STRIP 2021-08-23  1.12-210823.1955-003     10.0   \n",
      "11  A000001  ANATON TAB  STRIP 2021-09-20  2.11-210920.2012-139      0.0   \n",
      "12  A000001  ANATON TAB  STRIP 2021-10-13  1.11-211013.1609-006     10.0   \n",
      "13  A000001  ANATON TAB  STRIP 2021-10-27  2.11-211027.1633-088      0.0   \n",
      "14  A000001  ANATON TAB  STRIP 2021-11-10  2.13-211110.1228-002      0.0   \n",
      "\n",
      "    NILAI_MSK  QTY_KLR  NILAI_KLR KATEGORI  QTY_TOTAL  NILAI_TOTAL  \n",
      "0     2520.00      0.0        0.0    MASUK       10.0      2520.00  \n",
      "1        0.00      1.0     3000.0   KELUAR        1.0      3000.00  \n",
      "2        0.00      1.0     3000.0   KELUAR        1.0      3000.00  \n",
      "3        0.00      1.0     3000.0   KELUAR        1.0      3000.00  \n",
      "4        0.00      1.0     3000.0   KELUAR        1.0      3000.00  \n",
      "5        0.00      1.0     3000.0   KELUAR        1.0      3000.00  \n",
      "6        0.00      1.0     3000.0   KELUAR        1.0      3000.00  \n",
      "7        0.00      2.0     3000.0   KELUAR        2.0      3000.00  \n",
      "8        0.00      1.0     3000.0   KELUAR        1.0      3000.00  \n",
      "9        0.00      1.0     4000.0   KELUAR        1.0      4000.00  \n",
      "10    3139.15      0.0        0.0    MASUK       10.0      3139.15  \n",
      "11       0.00      1.0     4000.0   KELUAR        1.0      4000.00  \n",
      "12    3186.98      0.0        0.0    MASUK       10.0      3186.98  \n",
      "13       0.00      1.0     4000.0   KELUAR        1.0      4000.00  \n",
      "14       0.00      1.0     4000.0   KELUAR        1.0      4000.00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_number(x):\n",
    "    \"\"\"Konversi string angka format Indonesia menjadi float\"\"\"\n",
    "    if pd.isna(x) or str(x).strip() == '':\n",
    "        return 0.0\n",
    "    x = str(x).replace('.', '').replace(',', '.')\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# Lokasi file\n",
    "file_path = Path(\"pembelian.tsv\")\n",
    "\n",
    "# Baca file baris per baris\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data = []\n",
    "kode, nama, unit = '', '', ''\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "\n",
    "    # Deteksi baris header produk (contoh: A000001 ANATON TAB STRIP)\n",
    "    header_match = re.match(r'^([A-Z0-9]+)\\s+(.+?)\\s+(STRIP|BTL|BOX|PCS)$', line)\n",
    "    if header_match:\n",
    "        kode = header_match.group(1).strip()\n",
    "        nama = header_match.group(2).strip()\n",
    "        unit = header_match.group(3).strip()\n",
    "        continue\n",
    "\n",
    "    # Deteksi baris transaksi (dimulai tanggal DD-MM-YY)\n",
    "    date_match = re.match(r'^(\\d{2}-\\d{2}-\\d{2})', line)\n",
    "    if date_match:\n",
    "        parts = re.split(r'\\s{2,}', line)\n",
    "        tanggal = parts[0]\n",
    "        no_transaksi = parts[1] if len(parts) > 1 else ''\n",
    "\n",
    "        qty_msk = nilai_msk = qty_klr = nilai_klr = 0.0\n",
    "\n",
    "        # Format umum: tanggal | no_transaksi | qty | nilai\n",
    "        if len(parts) == 4:\n",
    "            # Cek kode transaksi (1. = masuk, 2. = keluar)\n",
    "            if no_transaksi.strip().startswith('1.'):\n",
    "                qty_msk = parse_number(parts[2])\n",
    "                nilai_msk = parse_number(parts[3])\n",
    "            elif no_transaksi.strip().startswith('2.'):\n",
    "                qty_klr = parse_number(parts[2])\n",
    "                nilai_klr = parse_number(parts[3])\n",
    "\n",
    "        elif len(parts) == 5:\n",
    "            # Bisa terjadi karena format tidak konsisten, kita cek pola juga\n",
    "            if no_transaksi.strip().startswith('1.'):\n",
    "                qty_msk = parse_number(parts[2])\n",
    "                nilai_msk = parse_number(parts[3])\n",
    "            elif no_transaksi.strip().startswith('2.'):\n",
    "                qty_klr = parse_number(parts[2])\n",
    "                nilai_klr = parse_number(parts[3])\n",
    "\n",
    "        elif len(parts) >= 6:\n",
    "            # Kalau keduanya ada (jarang terjadi)\n",
    "            qty_msk = parse_number(parts[2])\n",
    "            nilai_msk = parse_number(parts[3])\n",
    "            qty_klr = parse_number(parts[4])\n",
    "            nilai_klr = parse_number(parts[5])\n",
    "\n",
    "        # Tentukan kategori dan total\n",
    "        if qty_msk > 0:\n",
    "            kategori = 'MASUK'\n",
    "            qty_total = qty_msk\n",
    "            nilai_total = nilai_msk\n",
    "        elif qty_klr > 0:\n",
    "            kategori = 'KELUAR'\n",
    "            qty_total = qty_klr\n",
    "            nilai_total = nilai_klr\n",
    "        else:\n",
    "            kategori = 'LAINNYA'\n",
    "            qty_total = 0\n",
    "            nilai_total = 0\n",
    "\n",
    "        data.append({\n",
    "            'KODE': kode,\n",
    "            'NAMA_PRODUK': nama,\n",
    "            'UNIT': unit,\n",
    "            'TANGGAL': pd.to_datetime(tanggal, format='%d-%m-%y', errors='coerce'),\n",
    "            'NO_TRANSAKSI': no_transaksi,\n",
    "            'QTY_MSK': qty_msk,\n",
    "            'NILAI_MSK': nilai_msk,\n",
    "            'QTY_KLR': qty_klr,\n",
    "            'NILAI_KLR': nilai_klr,\n",
    "            'KATEGORI': kategori,\n",
    "            'QTY_TOTAL': qty_total,\n",
    "            'NILAI_TOTAL': nilai_total\n",
    "        })\n",
    "\n",
    "# Buat DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Urutkan berdasarkan kode dan tanggal\n",
    "df = df.sort_values(by=[\"KODE\", \"TANGGAL\"]).reset_index(drop=True)\n",
    "\n",
    "# Simpan hasil ke CSV\n",
    "output_path = \"pembelian_final_fix.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ File '{output_path}' berhasil dibuat!\")\n",
    "print(df.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f809583a",
   "metadata": {},
   "source": [
    "### Perubahan Struktur Dataset Stok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e84ac4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File 'stok_final_fix.csv' berhasil dibuat!\n",
      "      KODE         NAMA_PRODUK LOKASI  QTY_STOK   UNIT\n",
      "0  A000001          ANATON TAB   ETL1      12.0  STRIP\n",
      "1   A00001       ACTIVED HIJAU  ETL3A       2.0    BTL\n",
      "2  A000012  APIALYS SYR 100 ML  ETL3A       2.0    BTL\n",
      "3  A000014     ALKOHOL 1000 ML  ETL3B       7.0    BTL\n",
      "4  A000016     ALLOPURINOL 300   RAK2      40.0  STRIP\n",
      "5  A000018   ATORVASTATIN 10MG   RAK2       6.0  STRIP\n",
      "6   A00004     ACYCLOVIR 200MG   RAK2      13.0  STRIP\n",
      "7  A000040         MEFIX 500MG   RAK1       9.0  STRIP\n",
      "8   A00005     ACYCLOVIR 400MG   RAK2      21.0  STRIP\n",
      "9  A000066       ANDALAN KB FE   RAK4      35.0  STRIP\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# === Fungsi bantu untuk parsing angka format Indonesia ===\n",
    "def parse_number(x):\n",
    "    \"\"\"Konversi string angka format Indonesia menjadi float\"\"\"\n",
    "    if pd.isna(x) or str(x).strip() == '':\n",
    "        return 0.0\n",
    "    x = str(x).replace('.', '').replace(',', '.')\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# === Lokasi file input ===\n",
    "file_path = Path(\"stok.tsv\")\n",
    "\n",
    "# Baca file baris per baris\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "data = []\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "\n",
    "    # Lewati baris header\n",
    "    if line.startswith(\"KODE\") or line.startswith(\"Kode\"):\n",
    "        continue\n",
    "\n",
    "    # Pisahkan berdasarkan 2+ spasi\n",
    "    parts = re.split(r'\\s{2,}', line)\n",
    "    # Contoh hasil split:\n",
    "    # ['A000001', 'ANATON TAB', 'ETL1', '12,00', 'STRIP']\n",
    "\n",
    "    if len(parts) >= 5:\n",
    "        kode = parts[0].strip()\n",
    "        nama_produk = parts[1].strip()\n",
    "        lokasi = parts[2].strip()\n",
    "        qty_stok = parse_number(parts[3])\n",
    "        unit = parts[4].strip()\n",
    "\n",
    "        data.append({\n",
    "            'KODE': kode,\n",
    "            'NAMA_PRODUK': nama_produk,\n",
    "            'LOKASI': lokasi,\n",
    "            'QTY_STOK': qty_stok,\n",
    "            'UNIT': unit\n",
    "        })\n",
    "\n",
    "# Buat DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Urutkan berdasarkan KODE\n",
    "df = df.sort_values(by=[\"KODE\"]).reset_index(drop=True)\n",
    "\n",
    "# Simpan ke CSV\n",
    "output_path = \"stok_final_fix.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ File '{output_path}' berhasil dibuat!\")\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d118e803",
   "metadata": {},
   "source": [
    "## Proses Pengecekan Dataset Pembelian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468bfbb8",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8249de22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KODE</th>\n",
       "      <th>NAMA_PRODUK</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TANGGAL</th>\n",
       "      <th>NO_TRANSAKSI</th>\n",
       "      <th>QTY_MSK</th>\n",
       "      <th>NILAI_MSK</th>\n",
       "      <th>QTY_KLR</th>\n",
       "      <th>NILAI_KLR</th>\n",
       "      <th>KATEGORI</th>\n",
       "      <th>QTY_TOTAL</th>\n",
       "      <th>NILAI_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A000001</td>\n",
       "      <td>ANATON TAB</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>1.13-210706.0908-003</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MASUK</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A000001</td>\n",
       "      <td>ANATON TAB</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>2.6-210712.1519-097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>KELUAR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A000001</td>\n",
       "      <td>ANATON TAB</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>2.11-210712.1633-013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>KELUAR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A000001</td>\n",
       "      <td>ANATON TAB</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>2.13-210712.1807-013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>KELUAR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A000001</td>\n",
       "      <td>ANATON TAB</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>2.11-210712.1855-018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>KELUAR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          KODE NAMA_PRODUK   UNIT     TANGGAL          NO_TRANSAKSI  QTY_MSK  \\\n",
       "0      A000001  ANATON TAB  STRIP  2021-07-06  1.13-210706.0908-003     10.0   \n",
       "1      A000001  ANATON TAB  STRIP  2021-07-12   2.6-210712.1519-097      0.0   \n",
       "2      A000001  ANATON TAB  STRIP  2021-07-12  2.11-210712.1633-013      0.0   \n",
       "3      A000001  ANATON TAB  STRIP  2021-07-12  2.13-210712.1807-013      0.0   \n",
       "4      A000001  ANATON TAB  STRIP  2021-07-12  2.11-210712.1855-018      0.0   \n",
       "\n",
       "   NILAI_MSK  QTY_KLR  NILAI_KLR KATEGORI  QTY_TOTAL  NILAI_TOTAL  \n",
       "0     2520.0      0.0        0.0    MASUK       10.0       2520.0  \n",
       "1        0.0      1.0     3000.0   KELUAR        1.0       3000.0  \n",
       "2        0.0      1.0     3000.0   KELUAR        1.0       3000.0  \n",
       "3        0.0      1.0     3000.0   KELUAR        1.0       3000.0  \n",
       "4        0.0      1.0     3000.0   KELUAR        1.0       3000.0  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Gunakan current working directory\n",
    "cwd = os.getcwd()\n",
    "file_path = os.path.join(cwd, \"pembelian_final_fix.csv\")  \n",
    "\n",
    "# Baca file CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Tampilkan 5 baris pertama\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec74c29",
   "metadata": {},
   "source": [
    "#### Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2d5297f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Informasi DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138364 entries, 0 to 138363\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0       KODE      138364 non-null  object \n",
      " 1   NAMA_PRODUK   138364 non-null  object \n",
      " 2   UNIT          138364 non-null  object \n",
      " 3   TANGGAL       138364 non-null  object \n",
      " 4   NO_TRANSAKSI  138364 non-null  object \n",
      " 5   QTY_MSK       138364 non-null  float64\n",
      " 6   NILAI_MSK     138364 non-null  float64\n",
      " 7   QTY_KLR       138364 non-null  float64\n",
      " 8   NILAI_KLR     138364 non-null  float64\n",
      " 9   KATEGORI      138364 non-null  object \n",
      " 10  QTY_TOTAL     138364 non-null  float64\n",
      " 11  NILAI_TOTAL   138364 non-null  float64\n",
      "dtypes: float64(6), object(6)\n",
      "memory usage: 12.7+ MB\n",
      "\n",
      "📌 Tipe Data Kolom:\n",
      "    KODE         object\n",
      "NAMA_PRODUK      object\n",
      "UNIT             object\n",
      "TANGGAL          object\n",
      "NO_TRANSAKSI     object\n",
      "QTY_MSK         float64\n",
      "NILAI_MSK       float64\n",
      "QTY_KLR         float64\n",
      "NILAI_KLR       float64\n",
      "KATEGORI         object\n",
      "QTY_TOTAL       float64\n",
      "NILAI_TOTAL     float64\n",
      "dtype: object\n",
      "\n",
      "📌 Cek Missing Value:\n",
      "    KODE        0\n",
      "NAMA_PRODUK     0\n",
      "UNIT            0\n",
      "TANGGAL         0\n",
      "NO_TRANSAKSI    0\n",
      "QTY_MSK         0\n",
      "NILAI_MSK       0\n",
      "QTY_KLR         0\n",
      "NILAI_KLR       0\n",
      "KATEGORI        0\n",
      "QTY_TOTAL       0\n",
      "NILAI_TOTAL     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"📌 Informasi DataFrame:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n📌 Tipe Data Kolom:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n📌 Cek Missing Value:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e21b02",
   "metadata": {},
   "source": [
    "#### Konversi Tipe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7f523dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    KODE                object\n",
       "NAMA_PRODUK             object\n",
       "UNIT                    object\n",
       "TANGGAL         datetime64[ns]\n",
       "NO_TRANSAKSI            object\n",
       "QTY_MSK                float64\n",
       "NILAI_MSK              float64\n",
       "QTY_KLR                float64\n",
       "NILAI_KLR              float64\n",
       "KATEGORI                object\n",
       "QTY_TOTAL              float64\n",
       "NILAI_TOTAL            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Konversi kolom tanggal\n",
    "df['TANGGAL'] = pd.to_datetime(df['TANGGAL'], errors='coerce')\n",
    "\n",
    "# Kolom numerik\n",
    "num_cols = ['QTY_MSK', 'NILAI_MSK', 'QTY_KLR', 'NILAI_KLR', 'QTY_TOTAL', 'NILAI_TOTAL']\n",
    "for col in num_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Kolom teks\n",
    "str_cols = ['KODE', 'NAMA_PRODUK', 'UNIT', 'NO_TRANSAKSI', 'KATEGORI']\n",
    "for col in str_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ff9d6",
   "metadata": {},
   "source": [
    "#### Cek duplikasi berdasarkan NO_TRANSAKSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "573149cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Jumlah duplikasi No Transaksi   : 111749\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KODE</th>\n",
       "      <th>NAMA_PRODUK</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>TANGGAL</th>\n",
       "      <th>NO_TRANSAKSI</th>\n",
       "      <th>QTY_MSK</th>\n",
       "      <th>NILAI_MSK</th>\n",
       "      <th>QTY_KLR</th>\n",
       "      <th>NILAI_KLR</th>\n",
       "      <th>KATEGORI</th>\n",
       "      <th>QTY_TOTAL</th>\n",
       "      <th>NILAI_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136190</th>\n",
       "      <td>Y000001</td>\n",
       "      <td>YUSIMOX SYR</td>\n",
       "      <td>BTL</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>-----1.12-210414.1355-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LAINNYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36016</th>\n",
       "      <td>E0000055</td>\n",
       "      <td>ETADEX 0,5</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>-----1.12-210414.1355-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LAINNYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48284</th>\n",
       "      <td>H0000006</td>\n",
       "      <td>HEROCYN TALK 85G</td>\n",
       "      <td>BTL</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>-----1.12-210414.1355-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LAINNYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132248</th>\n",
       "      <td>V0000025</td>\n",
       "      <td>VITALONG C (4)</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>-----1.12-210414.1355-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LAINNYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138169</th>\n",
       "      <td>Z000006</td>\n",
       "      <td>ZAMBUK</td>\n",
       "      <td>PCS</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>-----1.12-210414.1355-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LAINNYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75336</th>\n",
       "      <td>M0000060</td>\n",
       "      <td>MYLANTA SYR (B)</td>\n",
       "      <td>BTL</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>-----1.12-210414.1355-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LAINNYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74579</th>\n",
       "      <td>M0000055</td>\n",
       "      <td>MYLANTA SYR (K)</td>\n",
       "      <td>BTL</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>-----1.12-210414.1355-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LAINNYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74038</th>\n",
       "      <td>M0000050</td>\n",
       "      <td>MOLEXFLU</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>-----1.12-210414.1355-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LAINNYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53842</th>\n",
       "      <td>I00000028</td>\n",
       "      <td>IMBOOST SYR 120ML</td>\n",
       "      <td>BTL</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>-----1.12-210414.1355-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LAINNYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106620</th>\n",
       "      <td>P0000197</td>\n",
       "      <td>POLOFAR PLUS</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>-----1.12-210414.1355-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LAINNYA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             KODE        NAMA_PRODUK   UNIT    TANGGAL  \\\n",
       "136190    Y000001        YUSIMOX SYR    BTL 2021-04-14   \n",
       "36016    E0000055         ETADEX 0,5  STRIP 2021-04-14   \n",
       "48284    H0000006   HEROCYN TALK 85G    BTL 2021-04-14   \n",
       "132248   V0000025     VITALONG C (4)  STRIP 2021-04-14   \n",
       "138169    Z000006             ZAMBUK    PCS 2021-04-14   \n",
       "75336    M0000060    MYLANTA SYR (B)    BTL 2021-04-14   \n",
       "74579    M0000055    MYLANTA SYR (K)    BTL 2021-04-14   \n",
       "74038    M0000050           MOLEXFLU  STRIP 2021-04-14   \n",
       "53842   I00000028  IMBOOST SYR 120ML    BTL 2021-04-14   \n",
       "106620   P0000197       POLOFAR PLUS  STRIP 2021-04-14   \n",
       "\n",
       "                     NO_TRANSAKSI  QTY_MSK  NILAI_MSK  QTY_KLR  NILAI_KLR  \\\n",
       "136190  -----1.12-210414.1355-001      0.0        0.0      0.0        0.0   \n",
       "36016   -----1.12-210414.1355-001      0.0        0.0      0.0        0.0   \n",
       "48284   -----1.12-210414.1355-001      0.0        0.0      0.0        0.0   \n",
       "132248  -----1.12-210414.1355-001      0.0        0.0      0.0        0.0   \n",
       "138169  -----1.12-210414.1355-001      0.0        0.0      0.0        0.0   \n",
       "75336   -----1.12-210414.1355-001      0.0        0.0      0.0        0.0   \n",
       "74579   -----1.12-210414.1355-001      0.0        0.0      0.0        0.0   \n",
       "74038   -----1.12-210414.1355-001      0.0        0.0      0.0        0.0   \n",
       "53842   -----1.12-210414.1355-001      0.0        0.0      0.0        0.0   \n",
       "106620  -----1.12-210414.1355-001      0.0        0.0      0.0        0.0   \n",
       "\n",
       "       KATEGORI  QTY_TOTAL  NILAI_TOTAL  \n",
       "136190  LAINNYA        0.0          0.0  \n",
       "36016   LAINNYA        0.0          0.0  \n",
       "48284   LAINNYA        0.0          0.0  \n",
       "132248  LAINNYA        0.0          0.0  \n",
       "138169  LAINNYA        0.0          0.0  \n",
       "75336   LAINNYA        0.0          0.0  \n",
       "74579   LAINNYA        0.0          0.0  \n",
       "74038   LAINNYA        0.0          0.0  \n",
       "53842   LAINNYA        0.0          0.0  \n",
       "106620  LAINNYA        0.0          0.0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cek duplikasi berdasarkan NO_TRANSAKSI\n",
    "duplikat_no_transaksi = df[df.duplicated(subset=['NO_TRANSAKSI'], keep=False)]\n",
    "\n",
    "print(f\"📌 Jumlah duplikasi No Transaksi   : {duplikat_no_transaksi.shape[0]}\")\n",
    "\n",
    "# Tampilkan sebagian contoh duplikasi\n",
    "duplikat_no_transaksi.sort_values('NO_TRANSAKSI').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61050777",
   "metadata": {},
   "source": [
    "#### Menghapus Duplikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5b83945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Jumlah data setelah hapus duplikasi: 59823\n"
     ]
    }
   ],
   "source": [
    "# Hapus duplikasi dengan mempertahankan baris pertama\n",
    "df = df.drop_duplicates(subset=['NO_TRANSAKSI'], keep='first')\n",
    "\n",
    "print(f\"✅ Jumlah data setelah hapus duplikasi: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ed69e",
   "metadata": {},
   "source": [
    "#### Deteksi Inkonsistensi Nama Produk per Kode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f0c2e1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['    KODE', 'NAMA_PRODUK', 'UNIT', 'TANGGAL', 'NO_TRANSAKSI', 'QTY_MSK', 'NILAI_MSK', 'QTY_KLR', 'NILAI_KLR', 'KATEGORI', 'QTY_TOTAL', 'NILAI_TOTAL']\n",
      "['KODE', 'NAMA_PRODUK', 'UNIT', 'TANGGAL', 'NO_TRANSAKSI', 'QTY_MSK', 'NILAI_MSK', 'QTY_KLR', 'NILAI_KLR', 'KATEGORI', 'QTY_TOTAL', 'NILAI_TOTAL']\n",
      "📌 Jumlah kode inkonsisten nama    : 0\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n",
    "\n",
    "df.columns = df.columns.str.strip().str.upper()\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Group by KODE → hitung berapa nama unik per kode\n",
    "kode_nama_group = df.groupby('KODE')['NAMA_PRODUK'].nunique()\n",
    "kode_nama_tidak_konsisten = kode_nama_group[kode_nama_group > 1]\n",
    "\n",
    "print(f\"📌 Jumlah kode inkonsisten nama    : {len(kode_nama_tidak_konsisten)}\")\n",
    "\n",
    "# Tampilkan nama-nama produk untuk setiap kode yang bermasalah\n",
    "for kode in kode_nama_tidak_konsisten.index:\n",
    "    print(f\"\\nKode {kode} punya nama produk:\")\n",
    "    print(df[df['KODE'] == kode]['NAMA_PRODUK'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f63044",
   "metadata": {},
   "source": [
    "#### Cek No Transaksi yang Tanggalnya Beda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ab91669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Jumlah No Transaksi beda tanggal: 0\n"
     ]
    }
   ],
   "source": [
    "no_transaksi_group = df.groupby('NO_TRANSAKSI')['TANGGAL'].nunique()\n",
    "no_transaksi_beda_tanggal = no_transaksi_group[no_transaksi_group > 1]\n",
    "\n",
    "print(f\"📌 Jumlah No Transaksi beda tanggal: {len(no_transaksi_beda_tanggal)}\")\n",
    "\n",
    "# Tampilkan jika ada\n",
    "if len(no_transaksi_beda_tanggal) > 0:\n",
    "    print(df[df['NO_TRANSAKSI'].isin(no_transaksi_beda_tanggal.index)].sort_values('NO_TRANSAKSI'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dbea3233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Rekapitulasi Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KODE</th>\n",
       "      <th>NAMA_PRODUK</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>QTY_MSK</th>\n",
       "      <th>NILAI_MSK</th>\n",
       "      <th>QTY_KLR</th>\n",
       "      <th>NILAI_KLR</th>\n",
       "      <th>QTY_TOTAL</th>\n",
       "      <th>NILAI_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A000001</td>\n",
       "      <td>ANATON TAB</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8846.13</td>\n",
       "      <td>18.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>68846.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00000156</td>\n",
       "      <td>zz</td>\n",
       "      <td>BTL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14355.43</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>66855.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00000157</td>\n",
       "      <td>z</td>\n",
       "      <td>BTL</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21425.19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>171425.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A000002</td>\n",
       "      <td>ASEPTIC PLUS SPRAY</td>\n",
       "      <td>BTL</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11000.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00001</td>\n",
       "      <td>ACTIVED HIJAU</td>\n",
       "      <td>BTL</td>\n",
       "      <td>20.0</td>\n",
       "      <td>527359.96</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1120000.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1647359.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A000011</td>\n",
       "      <td>ALLERIN EXP</td>\n",
       "      <td>BTL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A000012</td>\n",
       "      <td>APIALYS SYR 100 ML</td>\n",
       "      <td>BTL</td>\n",
       "      <td>18.0</td>\n",
       "      <td>575784.53</td>\n",
       "      <td>16.0</td>\n",
       "      <td>649000.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1224784.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A000014</td>\n",
       "      <td>ALKOHOL 1000 ML</td>\n",
       "      <td>BTL</td>\n",
       "      <td>20.0</td>\n",
       "      <td>195375.16</td>\n",
       "      <td>25.0</td>\n",
       "      <td>966000.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1161375.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A000016</td>\n",
       "      <td>ALLOPURINOL 300</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>230.0</td>\n",
       "      <td>64728.45</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1032000.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>1096728.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A000018</td>\n",
       "      <td>ATORVASTATIN 10MG</td>\n",
       "      <td>STRIP</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61879.02</td>\n",
       "      <td>9.0</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>358879.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            KODE         NAMA_PRODUK   UNIT  QTY_MSK  NILAI_MSK  QTY_KLR  \\\n",
       "0        A000001          ANATON TAB  STRIP     30.0    8846.13     18.0   \n",
       "1      A00000156                  zz    BTL      4.0   14355.43      4.0   \n",
       "2      A00000157                   z    BTL      3.0   21425.19      6.0   \n",
       "3        A000002  ASEPTIC PLUS SPRAY    BTL      3.0   11000.00      3.0   \n",
       "4         A00001       ACTIVED HIJAU    BTL     20.0  527359.96     19.0   \n",
       "5        A000011         ALLERIN EXP    BTL      0.0       0.00      3.0   \n",
       "6        A000012  APIALYS SYR 100 ML    BTL     18.0  575784.53     16.0   \n",
       "7        A000014     ALKOHOL 1000 ML    BTL     20.0  195375.16     25.0   \n",
       "8        A000016     ALLOPURINOL 300  STRIP    230.0   64728.45    210.0   \n",
       "9        A000018   ATORVASTATIN 10MG  STRIP      9.0   61879.02      9.0   \n",
       "\n",
       "   NILAI_KLR  QTY_TOTAL  NILAI_TOTAL  \n",
       "0    60000.0       48.0     68846.13  \n",
       "1    52500.0        8.0     66855.43  \n",
       "2   150000.0        9.0    171425.19  \n",
       "3    30000.0        6.0     41000.00  \n",
       "4  1120000.0       39.0   1647359.96  \n",
       "5    40500.0        3.0     40500.00  \n",
       "6   649000.0       34.0   1224784.53  \n",
       "7   966000.0       45.0   1161375.16  \n",
       "8  1032000.0      440.0   1096728.45  \n",
       "9   297000.0       18.0    358879.02  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rekap = df.groupby(['KODE', 'NAMA_PRODUK', 'UNIT']).agg({\n",
    "    'QTY_MSK': 'sum',\n",
    "    'NILAI_MSK': 'sum',\n",
    "    'QTY_KLR': 'sum',\n",
    "    'NILAI_KLR': 'sum',\n",
    "    'QTY_TOTAL': 'sum',\n",
    "    'NILAI_TOTAL': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"📊 Rekapitulasi Data:\")\n",
    "rekap.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9632d0",
   "metadata": {},
   "source": [
    "#### Standarisasi Format Teks dan Satuan Numerik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9943f6bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'QTY_MSK'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Datmin UTS\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'QTY_MSK'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Pastikan semua numerik, hilangkan anomali karakter seperti koma, titik salah posisi\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m num_cols:\n\u001b[32m      7\u001b[39m     df[col] = (\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      9\u001b[39m         .astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m     10\u001b[39m         .str.replace(\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m, regex=\u001b[38;5;28;01mFalse\u001b[39;00m)  \n\u001b[32m     11\u001b[39m         .str.replace(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[^\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.]\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, regex=\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[32m     12\u001b[39m     )\n\u001b[32m     13\u001b[39m     df[col] = pd.to_numeric(df[col], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m).round(\u001b[32m2\u001b[39m) \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Ubah huruf besar semua, hilangkan spasi berlebih, dan karakter tidak penting\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Datmin UTS\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Datmin UTS\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'QTY_MSK'"
     ]
    }
   ],
   "source": [
    "# Daftar kolom teks\n",
    "text_cols = ['KODE', 'NAMA_PRODUK', 'UNIT', 'KATEGORI', 'NO_TRANSAKSI']\n",
    "num_cols = ['QTY_MSK', 'NILAI_MSK', 'QTY_KLR', 'NILAI_KLR', 'QTY_TOTAL', 'NILAI_TOTAL']\n",
    "\n",
    "# Pastikan semua numerik, hilangkan anomali karakter seperti koma, titik salah posisi\n",
    "for col in num_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.replace(',', '.', regex=False)  \n",
    "        .str.replace(r'[^\\d\\.]', '', regex=True)  \n",
    "    )\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').round(2) \n",
    "\n",
    "# Ubah huruf besar semua, hilangkan spasi berlebih, dan karakter tidak penting\n",
    "for col in text_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.replace(r'\\s+', ' ', regex=True)  # hilangkan spasi ganda\n",
    "        .str.upper()\n",
    "    )\n",
    "    \n",
    "df.loc[:, 'TANGGAL'] = pd.to_datetime(df['TANGGAL'], errors='coerce', format='%Y-%m-%d')\n",
    "\n",
    "df.loc[:, 'KODE'] = (\n",
    "    df['KODE']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(r'[^A-Z0-9]', '', regex=True)   # hanya huruf besar & angka\n",
    "    .str.upper()\n",
    ")\n",
    "\n",
    "def valid_kode(k):\n",
    "    return bool(re.match(r'^[A-Z0-9]{3,12}$', str(k).strip()))\n",
    "\n",
    "df.loc[:, 'KODE_VALID'] = df['KODE'].apply(valid_kode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ed9a3",
   "metadata": {},
   "source": [
    "#### Validasi Format Tanggal dan Kode Obat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dd7cce86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Tanggal tidak valid: 0 baris\n",
      "⚠️ Kode obat tidak valid: 0 baris\n"
     ]
    }
   ],
   "source": [
    "# Konversi tanggal dan validasi\n",
    "df['TANGGAL'] = pd.to_datetime(df['TANGGAL'], errors='coerce')\n",
    "invalid_date = df[df['TANGGAL'].isna()]\n",
    "invalid_kode = df[df['KODE_VALID'] == False]\n",
    "\n",
    "print(f\"⚠️ Tanggal tidak valid: {len(invalid_date)} baris\")\n",
    "print(f\"⚠️ Kode obat tidak valid: {len(invalid_kode)} baris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1e288",
   "metadata": {},
   "source": [
    "#### RULE-BASED METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "34af039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0484c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧩 [Rule-Based Detection] Ditemukan 0 baris anomali berdasarkan aturan logika.\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aturan logika:\n",
    "\n",
    "# - Jika KATEGORI = MASUK maka QTY_MSK > 0 dan QTY_KLR = 0\n",
    "# - Jika KATEGORI = KELUAR maka QTY_KLR > 0 dan QTY_MSK = 0\n",
    "# - Nilai total tidak boleh negatif\n",
    "\n",
    "df.loc[:, 'RULE_FLAG'] = np.where(\n",
    "    ((df['KATEGORI'] == 'MASUK') & ((df['QTY_MSK'] <= 0) | (df['QTY_KLR'] != 0))) |\n",
    "    ((df['KATEGORI'] == 'KELUAR') & ((df['QTY_KLR'] <= 0) | (df['QTY_MSK'] != 0))) |\n",
    "    (df['NILAI_TOTAL'] < 0),\n",
    "    True, False\n",
    ")\n",
    "\n",
    "rule_count = df['RULE_FLAG'].sum()\n",
    "print(f\"🧩 [Rule-Based Detection] Ditemukan {rule_count} baris anomali berdasarkan aturan logika.\")\n",
    "if rule_count > 0:\n",
    "    print(df[df['RULE_FLAG']].head(5))\n",
    "print(\"--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c4eb9f",
   "metadata": {},
   "source": [
    "#### CONSTRAINT-BASED DETECTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "62299cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📏 [Constraint-Based Detection] Ditemukan 0 baris melanggar batas wajar.\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.loc[:, 'CONSTRAINT_FLAG'] = np.where(\n",
    "    (df['QTY_TOTAL'] > 10000) | \n",
    "    (df['NILAI_TOTAL'] > 1_000_000) |\n",
    "    (df['TANGGAL'].isna()),\n",
    "    True, False\n",
    ")\n",
    "\n",
    "constraint_count = df['CONSTRAINT_FLAG'].sum()\n",
    "print(f\"📏 [Constraint-Based Detection] Ditemukan {constraint_count} baris melanggar batas wajar.\")\n",
    "if constraint_count > 0:\n",
    "    print(df[df['CONSTRAINT_FLAG']].head(5))\n",
    "print(\"--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447aaba8",
   "metadata": {},
   "source": [
    "#### STATISTICAL / PATTERN-BASED DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fb886edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acerl\\AppData\\Local\\Temp\\ipykernel_14772\\615633583.py:29: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('NAMA_PRODUK', group_keys=False).apply(lambda g: detect_outlier_group(g, col))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 [Statistical Detection] (Per Produk)\n",
      "   Anomali QTY_TOTAL: 1240\n",
      "   Anomali NILAI_TOTAL: 975\n",
      "   Total anomali terdeteksi: 2215\n",
      "✅ Jumlah data dikoreksi otomatis (statistik): 1827\n",
      "\n",
      "🔍 Contoh hasil koreksi outlier statistik:\n",
      "        KODE         NAMA_PRODUK  QTY_TOTAL  QTY_TOTAL_FIX_STAT  NILAI_TOTAL  \\\n",
      "49    A00001       ACTIVED HIJAU        3.0                 1.0     49666.67   \n",
      "82   A000012  APIALYS SYR 100 ML        1.0                 1.0     49000.00   \n",
      "84   A000012  APIALYS SYR 100 ML        2.0                 1.0     35398.37   \n",
      "93   A000012  APIALYS SYR 100 ML        2.0                 1.0     35392.92   \n",
      "125  A000014     ALKOHOL 1000 ML        6.0                 1.0     32500.00   \n",
      "153  A000016     ALLOPURINOL 300       20.0                 1.0      4300.01   \n",
      "155  A000016     ALLOPURINOL 300        0.0                 0.0         0.00   \n",
      "181  A000016     ALLOPURINOL 300        0.0                 0.0         0.00   \n",
      "196  A000016     ALLOPURINOL 300       20.0                 1.0      4299.90   \n",
      "219  A000016     ALLOPURINOL 300        0.0                 0.0         0.00   \n",
      "\n",
      "     NILAI_TOTAL_FIX_STAT  STAT_FLAG_QTY_TOTAL  STAT_FLAG_NILAI_TOTAL  \n",
      "49               49666.67                 True                  False  \n",
      "82               40000.00                False                   True  \n",
      "84               35398.37                 True                  False  \n",
      "93               35392.92                 True                  False  \n",
      "125              32500.00                 True                  False  \n",
      "153               4300.01                 True                  False  \n",
      "155               6000.00                False                   True  \n",
      "181               6000.00                False                   True  \n",
      "196               4299.90                 True                  False  \n",
      "219               6000.00                False                   True  \n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acerl\\AppData\\Local\\Temp\\ipykernel_14772\\615633583.py:29: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('NAMA_PRODUK', group_keys=False).apply(lambda g: detect_outlier_group(g, col))\n"
     ]
    }
   ],
   "source": [
    "# PENANGANAN ANOMALI STATISTIK PER PRODUK (Final Tanpa Error)\n",
    "\n",
    "# Pastikan kolom yang dibutuhkan tersedia\n",
    "if 'NILAI_TOTAL' not in df.columns:\n",
    "    df['NILAI_TOTAL'] = df.get('NILAI_TOTAL_FIX', df['NILAI_MSK'] - df['NILAI_KLR'])\n",
    "\n",
    "if 'QTY_TOTAL' not in df.columns:\n",
    "    df['QTY_TOTAL'] = df.get('QTY_TOTAL_FIX', df['QTY_MSK'] - df['QTY_KLR'])\n",
    "\n",
    "# Fungsi deteksi dan perbaikan outlier per produk\n",
    "def detect_outlier_group(df_group, col):\n",
    "    mean = df_group[col].mean()\n",
    "    median = df_group[col].median()\n",
    "    std = df_group[col].std(ddof=0)\n",
    "\n",
    "    if len(df_group) < 3 or std == 0 or np.isnan(std):\n",
    "        df_group[f'STAT_FLAG_{col}'] = False\n",
    "        df_group[f'{col}_FIX_STAT'] = df_group[col]\n",
    "        return df_group\n",
    "\n",
    "    zscore = (df_group[col] - mean) / std\n",
    "    df_group[f'STAT_FLAG_{col}'] = abs(zscore) > 3\n",
    "    df_group[f'{col}_FIX_STAT'] = np.where(abs(zscore) > 3, median, df_group[col])\n",
    "    return df_group\n",
    "\n",
    "# Terapkan ke tiap kolom numerik per produk (tanpa subset kolom)\n",
    "for col in ['QTY_TOTAL', 'NILAI_TOTAL']:\n",
    "    if col in df.columns:\n",
    "        df = df.groupby('NAMA_PRODUK', group_keys=False).apply(lambda g: detect_outlier_group(g, col))\n",
    "\n",
    "# LAPORAN HASIL DETEKSI DAN PERBAIKAN\n",
    "\n",
    "stat_anom_qty = df['STAT_FLAG_QTY_TOTAL'].sum() if 'STAT_FLAG_QTY_TOTAL' in df else 0\n",
    "stat_anom_nilai = df['STAT_FLAG_NILAI_TOTAL'].sum() if 'STAT_FLAG_NILAI_TOTAL' in df else 0\n",
    "total_anom = stat_anom_qty + stat_anom_nilai\n",
    "\n",
    "df['DIKOREKSI_STAT'] = df.get('STAT_FLAG_QTY_TOTAL', False) | df.get('STAT_FLAG_NILAI_TOTAL', False)\n",
    "\n",
    "print(f\"📊 [Statistical Detection] (Per Produk)\")\n",
    "print(f\"   Anomali QTY_TOTAL: {stat_anom_qty}\")\n",
    "print(f\"   Anomali NILAI_TOTAL: {stat_anom_nilai}\")\n",
    "print(f\"   Total anomali terdeteksi: {total_anom}\")\n",
    "print(f\"✅ Jumlah data dikoreksi otomatis (statistik): {df['DIKOREKSI_STAT'].sum()}\\n\")\n",
    "\n",
    "# Tampilkan contoh hasil koreksi\n",
    "print(\"🔍 Contoh hasil koreksi outlier statistik:\")\n",
    "cols_show = [c for c in [\n",
    "    'KODE', 'NAMA_PRODUK',\n",
    "    'QTY_TOTAL', 'QTY_TOTAL_FIX_STAT',\n",
    "    'NILAI_TOTAL', 'NILAI_TOTAL_FIX_STAT',\n",
    "    'STAT_FLAG_QTY_TOTAL', 'STAT_FLAG_NILAI_TOTAL'\n",
    "] if c in df.columns]\n",
    "print(df[df['DIKOREKSI_STAT']].head(10)[cols_show])\n",
    "print(\"--------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d030d9d2",
   "metadata": {},
   "source": [
    "#### CLUSTERING-BASED DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7a481379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "e:\\KIKI\\Data Mining\\UTS-Penambangan-Data\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧮 [Clustering-Based Detection per Produk] Ditemukan 1949 data jauh dari pusat cluster produk.\n",
      "🩺 1949 data telah dikoreksi mendekati centroid cluster produk masing-masing.\n",
      "\n",
      "        KODE         NAMA_PRODUK  QTY_TOTAL  NILAI_TOTAL  \\\n",
      "48    A00001       ACTIVED HIJAU        3.0     49666.67   \n",
      "54    A00001       ACTIVED HIJAU        2.0     58550.17   \n",
      "80   A000012  APIALYS SYR 100 ML        1.0     49000.00   \n",
      "100  A000014     ALKOHOL 1000 ML        2.0     29275.55   \n",
      "110  A000014     ALKOHOL 1000 ML        3.0     42000.00   \n",
      "123  A000014     ALKOHOL 1000 ML        6.0     32500.00   \n",
      "151  A000016     ALLOPURINOL 300       20.0      4300.01   \n",
      "153  A000016     ALLOPURINOL 300        0.0         0.00   \n",
      "179  A000016     ALLOPURINOL 300        0.0         0.00   \n",
      "194  A000016     ALLOPURINOL 300       20.0      4299.90   \n",
      "\n",
      "     QTY_TOTAL_FIX_CLUSTER  NILAI_TOTAL_FIX_CLUSTER  CLUSTER  \\\n",
      "48                2.111111             52652.583333      0.0   \n",
      "54                2.111111             52652.583333      0.0   \n",
      "80                1.000000             38466.441333      0.0   \n",
      "100               3.333333             32562.526667      1.0   \n",
      "110               1.086957             42000.000000      0.0   \n",
      "123               3.333333             32562.526667      1.0   \n",
      "151              12.105263              3406.760526      1.0   \n",
      "153              12.105263              3406.760526      1.0   \n",
      "179              12.105263              3406.760526      1.0   \n",
      "194              12.105263              3406.760526      1.0   \n",
      "\n",
      "     DIKOREKSI_CLUSTER  \n",
      "48                True  \n",
      "54                True  \n",
      "80                True  \n",
      "100               True  \n",
      "110               True  \n",
      "123               True  \n",
      "151               True  \n",
      "153               True  \n",
      "179               True  \n",
      "194               True  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acerl\\AppData\\Local\\Temp\\ipykernel_14772\\1899491918.py:43: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('NAMA_PRODUK', group_keys=False).apply(clustering_per_produk).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# CLUSTERING-BASED DETECTION (Per Produk) + PENANGANAN\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "df = df.copy()\n",
    "df.loc[:, 'CLUSTER_FLAG'] = False\n",
    "df.loc[:, 'DIKOREKSI_CLUSTER'] = False\n",
    "df.loc[:, 'QTY_TOTAL_FIX_CLUSTER'] = df['QTY_TOTAL']\n",
    "df.loc[:, 'NILAI_TOTAL_FIX_CLUSTER'] = df['NILAI_TOTAL']\n",
    "\n",
    "# Fungsi deteksi + koreksi per produk\n",
    "def clustering_per_produk(group):\n",
    "    if len(group) < 4:\n",
    "        return group \n",
    "\n",
    "    X = group[['QTY_TOTAL', 'NILAI_TOTAL']].fillna(0)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # 2 cluster per produk\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "    group = group.copy()  \n",
    "    group['CLUSTER'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    distances = np.linalg.norm(X_scaled - centroids[group['CLUSTER']], axis=1)\n",
    "    threshold = distances.mean() + 2 * distances.std()\n",
    "    group['CLUSTER_FLAG'] = distances > threshold\n",
    "\n",
    "    # Koreksi nilai ekstrem\n",
    "    for i, row in group[group['CLUSTER_FLAG']].iterrows():\n",
    "        cid = row['CLUSTER']\n",
    "        centroid_unscaled = scaler.inverse_transform([centroids[cid]])[0]\n",
    "        group.at[i, 'QTY_TOTAL_FIX_CLUSTER'] = centroid_unscaled[0]\n",
    "        group.at[i, 'NILAI_TOTAL_FIX_CLUSTER'] = centroid_unscaled[1]\n",
    "        group.at[i, 'DIKOREKSI_CLUSTER'] = True\n",
    "\n",
    "    return group\n",
    "\n",
    "# Terapkan per produk (kompatibel semua pandas)\n",
    "df = df.groupby('NAMA_PRODUK', group_keys=False).apply(clustering_per_produk).reset_index(drop=True)\n",
    "\n",
    "# HASIL AKHIR\n",
    "outlier_count = df['CLUSTER_FLAG'].sum()\n",
    "fixed_count = df['DIKOREKSI_CLUSTER'].sum()\n",
    "\n",
    "print(f\"🧮 [Clustering-Based Detection per Produk] Ditemukan {outlier_count} data jauh dari pusat cluster produk.\")\n",
    "print(f\"🩺 {fixed_count} data telah dikoreksi mendekati centroid cluster produk masing-masing.\\n\")\n",
    "\n",
    "print(df[df['DIKOREKSI_CLUSTER']].head(10)[[\n",
    "    'KODE', 'NAMA_PRODUK', 'QTY_TOTAL', 'NILAI_TOTAL',\n",
    "    'QTY_TOTAL_FIX_CLUSTER', 'NILAI_TOTAL_FIX_CLUSTER',\n",
    "    'CLUSTER', 'DIKOREKSI_CLUSTER'\n",
    "]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c3ed0",
   "metadata": {},
   "source": [
    "#### CROSS-DATASET CONSISTENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b1ee3114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 [Cross-Dataset Consistency] Sebelum koreksi: 0 baris tidak konsisten.\n",
      "🧮 Setelah koreksi: 0 baris masih tidak konsisten.\n",
      "✅ Berhasil memperbaiki 0 baris data otomatis.\n",
      "\n",
      "      KODE NAMA_PRODUK KATEGORI  NILAI_MSK  NILAI_KLR  NILAI_TOTAL_BEFORE_FIX  \\\n",
      "0  A000001  ANATON TAB    MASUK     2520.0        0.0                  2520.0   \n",
      "1  A000001  ANATON TAB   KELUAR        0.0     3000.0                  3000.0   \n",
      "2  A000001  ANATON TAB   KELUAR        0.0     3000.0                  3000.0   \n",
      "3  A000001  ANATON TAB   KELUAR        0.0     3000.0                  3000.0   \n",
      "4  A000001  ANATON TAB   KELUAR        0.0     3000.0                  3000.0   \n",
      "5  A000001  ANATON TAB   KELUAR        0.0     3000.0                  3000.0   \n",
      "6  A000001  ANATON TAB   KELUAR        0.0     3000.0                  3000.0   \n",
      "7  A000001  ANATON TAB   KELUAR        0.0     3000.0                  3000.0   \n",
      "8  A000001  ANATON TAB   KELUAR        0.0     3000.0                  3000.0   \n",
      "9  A000001  ANATON TAB   KELUAR        0.0     4000.0                  4000.0   \n",
      "\n",
      "   NILAI_TOTAL_FIX_CONSIST  \n",
      "0                   2520.0  \n",
      "1                   3000.0  \n",
      "2                   3000.0  \n",
      "3                   3000.0  \n",
      "4                   3000.0  \n",
      "5                   3000.0  \n",
      "6                   3000.0  \n",
      "7                   3000.0  \n",
      "8                   3000.0  \n",
      "9                   4000.0  \n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CROSS-DATASET CONSISTENCY \n",
    "\n",
    "# Simpan nilai sebelum perbaikan\n",
    "df['NILAI_TOTAL_BEFORE_FIX'] = df['NILAI_TOTAL']\n",
    "\n",
    "# Fungsi logika nilai seharusnya berdasarkan kategori\n",
    "def nilai_seharusnya(row):\n",
    "    kategori = str(row['KATEGORI']).upper()\n",
    "    if kategori == 'MASUK':\n",
    "        return row['NILAI_MSK']\n",
    "    elif kategori == 'KELUAR':\n",
    "        return row['NILAI_KLR']\n",
    "    else:\n",
    "        return row['NILAI_MSK'] - row['NILAI_KLR']\n",
    "\n",
    "# Hitung nilai seharusnya\n",
    "df['NILAI_TOTAL_EXPECTED'] = df.apply(nilai_seharusnya, axis=1)\n",
    "\n",
    "# Deteksi inkonsistensi awal\n",
    "df['CONSIST_FLAG'] = abs(df['NILAI_TOTAL'] - df['NILAI_TOTAL_EXPECTED']) > 1e-6\n",
    "before_fix = df['CONSIST_FLAG'].sum()\n",
    "\n",
    "# Koreksi otomatis hanya untuk baris tidak konsisten\n",
    "df.loc[df['CONSIST_FLAG'], 'NILAI_TOTAL'] = df.loc[df['CONSIST_FLAG'], 'NILAI_TOTAL_EXPECTED']\n",
    "df['NILAI_TOTAL_FIX_CONSIST'] = df['NILAI_TOTAL']\n",
    "\n",
    "# Recheck setelah perbaikan\n",
    "df['CONSIST_FLAG_AFTER'] = abs(df['NILAI_TOTAL'] - df['NILAI_TOTAL_EXPECTED']) > 1e-6\n",
    "after_fix = df['CONSIST_FLAG_AFTER'].sum()\n",
    "\n",
    "# Laporan hasil perbaikan\n",
    "print(f\"🔗 [Cross-Dataset Consistency] Sebelum koreksi: {before_fix} baris tidak konsisten.\")\n",
    "print(f\"🧮 Setelah koreksi: {after_fix} baris masih tidak konsisten.\")\n",
    "print(f\"✅ Berhasil memperbaiki {before_fix - after_fix} baris data otomatis.\\n\")\n",
    "\n",
    "# Contoh hasil koreksi\n",
    "print(df[df['CONSIST_FLAG_AFTER'] == False].head(10)[[\n",
    "    'KODE', 'NAMA_PRODUK', 'KATEGORI',\n",
    "    'NILAI_MSK', 'NILAI_KLR',\n",
    "    'NILAI_TOTAL_BEFORE_FIX', 'NILAI_TOTAL_FIX_CONSIST'\n",
    "]])\n",
    "print(\"--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a45140aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Versi final bersih berhasil diekspor ke:\n",
      "📂 output\\dataset_final_bersih_20251020_145253.csv\n",
      "📊 Total baris: 59823 | Total kolom: 12\n"
     ]
    }
   ],
   "source": [
    "# HASIL AKHIR FINAL BERSIH\n",
    "\n",
    "cols_final = [\n",
    "    'KODE', 'NAMA_PRODUK', 'UNIT', 'TANGGAL', 'NO_TRANSAKSI',\n",
    "    'KATEGORI', 'QTY_MSK', 'NILAI_MSK', 'QTY_KLR', 'NILAI_KLR',\n",
    "    'QTY_TOTAL_FIX_STAT', 'NILAI_TOTAL_FIX_CONSIST'\n",
    "]\n",
    "\n",
    "df_clean = df[cols_final].copy()\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "output_dir = Path(\"output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = output_dir / f\"dataset_final_bersih_{timestamp}.csv\"\n",
    "\n",
    "df_clean.to_csv(output_path, index=False, encoding='utf-8-sig', float_format='%.2f')\n",
    "\n",
    "print(f\"✅ Versi final bersih berhasil diekspor ke:\\n📂 {output_path}\")\n",
    "print(f\"📊 Total baris: {len(df_clean)} | Total kolom: {len(df_clean.columns)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
